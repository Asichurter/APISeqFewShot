任务日志

# 4.8
- 测试NGram性能

- 测试了纯CNN结构和LSTM+CNN结构在NGram数据上（序列长度为100）的效果，结果
显示正确率大约在３４％左右徘徊，没有出现过拟合，损失值下降到1.4左右，且使用
CNN进行解码效果好于使用注意力

- 测试了在固定任务（给定任务seed）的情况下模型的效果，结果显示在固定任务上模型
能够拟合，但是出现过拟合现象。这说明并非模型不能捕获序列特征，而是无法捕获任务间
的元特征

- 固定embedding层的权重进行训练不能收敛

- 使用ProtoNet里面的Conv-4(2D)不能收敛

- Transformer使用CNN和自注意力归约都不能收敛

# 4.9 TODO

- 测试Transformer在本数据集上的fine-tuning（考虑使用原API名称） ×

# 4.9

- 在seq_len=50的数据集上，LSTM+CNN的表现比100更好，说明存在长序列噪声
的可能。但是短序列的过拟合现象更加明显，val_loss 保持在1.57左右的水平，
而train_loss已经下降到1.3左右的水平(1.png是CNN在先，2.png是CNN在LSTM后)

- 根据Mutiple Metric论文中指出的：可能任务间存在较大的差异(variation)，
导致common metric方法不能很好奏效

# 4.10 TODO

- 测试如ConvProtoNet, InductionNet和Hybrid-attention Net等其他模型


# 4.15

- 训练集没有很好收敛的原因也可能在于基于API的数据集进行跨任务学习的难度较高，
主要因为任务空间较大，采样比例小。于是测试减少meta-training的class数量，
检验训练正确率是否提升。结果显示，训练集类减少到20个时上升大概7-8%，减小到10
个类时正确率上升15%及以上，说明了该问题。

- 减少metatraining类数目的代价时元训练过程可能只在小任务空间中进行，从而
限制了模型的泛化能力。结果显示，验证正确率还是停留在35%-40%水平

